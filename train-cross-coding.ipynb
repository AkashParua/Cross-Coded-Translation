{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer , AutoConfig , AutoModelForSeq2SeqLM","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-20T22:26:45.193733Z","iopub.execute_input":"2023-10-20T22:26:45.194562Z","iopub.status.idle":"2023-10-20T22:26:47.011054Z","shell.execute_reply.started":"2023-10-20T22:26:45.194530Z","shell.execute_reply":"2023-10-20T22:26:47.010109Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_name = \"t5-small\"\nconfig = AutoConfig.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name , use_fast = True)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name , config = config)","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:26:49.267312Z","iopub.execute_input":"2023-10-20T22:26:49.267907Z","iopub.status.idle":"2023-10-20T22:27:03.466651Z","shell.execute_reply.started":"2023-10-20T22:26:49.267866Z","shell.execute_reply":"2023-10-20T22:27:03.465722Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f7ec9366d934d03acd9af507a2a3b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"774514b3bb2c4b589a67bfcb3849d933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a353862bf5b14e9782c7714b5811821e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf8c008a37249c2b3d5279b65f45a26"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af4c316bff794075b6e270c18111a90d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa1172e25a44ee88578b0f9fc98983a"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('findnitai/english-to-hinglish')","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:06.286353Z","iopub.execute_input":"2023-10-20T22:27:06.287123Z","iopub.status.idle":"2023-10-20T22:27:06.899035Z","shell.execute_reply.started":"2023-10-20T22:27:06.287086Z","shell.execute_reply":"2023-10-20T22:27:06.898132Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bbeb75769394ab5922dc2f179ae369e"}},"metadata":{}}]},{"cell_type":"code","source":"master = []\nfor line in dataset['train']['translation']:\n    master.append(line['en'])\n    master.append(line['hi_ng'])\n\ndef gen_training_data():\n    return (master[i : i+500]\n    for i in range(0, len(master), 500)\n    )\ntokenizer_training_data = gen_training_data()","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:11.141918Z","iopub.execute_input":"2023-10-20T22:27:11.142266Z","iopub.status.idle":"2023-10-20T22:27:13.446219Z","shell.execute_reply.started":"2023-10-20T22:27:11.142238Z","shell.execute_reply":"2023-10-20T22:27:13.445167Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer_training_data","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:17.833051Z","iopub.execute_input":"2023-10-20T22:27:17.833371Z","iopub.status.idle":"2023-10-20T22:27:17.839800Z","shell.execute_reply.started":"2023-10-20T22:27:17.833346Z","shell.execute_reply":"2023-10-20T22:27:17.838900Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<generator object gen_training_data.<locals>.<genexpr> at 0x7f8079eeb920>"},"metadata":{}}]},{"cell_type":"code","source":"trained_tokenizer = tokenizer.train_new_from_iterator(tokenizer_training_data , vocab_size = 32128)","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:20.467465Z","iopub.execute_input":"2023-10-20T22:27:20.467819Z","iopub.status.idle":"2023-10-20T22:27:30.821855Z","shell.execute_reply.started":"2023-10-20T22:27:20.467789Z","shell.execute_reply":"2023-10-20T22:27:30.820884Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\n\n","output_type":"stream"}]},{"cell_type":"code","source":"trained_tokenizer.save_pretrained(\"english_to_hinglish_tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:34.718852Z","iopub.execute_input":"2023-10-20T22:27:34.719604Z","iopub.status.idle":"2023-10-20T22:27:34.736786Z","shell.execute_reply.started":"2023-10-20T22:27:34.719562Z","shell.execute_reply":"2023-10-20T22:27:34.735906Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('english_to_hinglish_tokenizer/tokenizer_config.json',\n 'english_to_hinglish_tokenizer/special_tokens_map.json',\n 'english_to_hinglish_tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"source_prefix = \"Translate English to Hinglish : \"\nsource_lang = \"en\"\ntarget_lang = \"hi_ng\"\nmax_source_length = 128 \nmax_target_length = 128 # target and source length task dependent (translation, summary etc.)\npadding = \"max_length\" # padding to max length\nnum_epochs = 3","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:30:19.212428Z","iopub.execute_input":"2023-10-20T22:30:19.213082Z","iopub.status.idle":"2023-10-20T22:30:19.217713Z","shell.execute_reply.started":"2023-10-20T22:30:19.213050Z","shell.execute_reply":"2023-10-20T22:30:19.216684Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"dataset_dict = dataset.data","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:37.540477Z","iopub.execute_input":"2023-10-20T22:27:37.540821Z","iopub.status.idle":"2023-10-20T22:27:37.545136Z","shell.execute_reply.started":"2023-10-20T22:27:37.540795Z","shell.execute_reply":"2023-10-20T22:27:37.544124Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"output_json_path = \"english_to_hinglish.json\"","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:44.082679Z","iopub.execute_input":"2023-10-20T22:27:44.083048Z","iopub.status.idle":"2023-10-20T22:27:44.087489Z","shell.execute_reply.started":"2023-10-20T22:27:44.083017Z","shell.execute_reply":"2023-10-20T22:27:44.086394Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"formatted_dataset = [{'translation':{\"en\": example[\"en\"], \"hi_ng\": example[\"hi_ng\"]}} for example in dataset['train']['translation']]","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:46.693795Z","iopub.execute_input":"2023-10-20T22:27:46.694679Z","iopub.status.idle":"2023-10-20T22:27:49.247211Z","shell.execute_reply.started":"2023-10-20T22:27:46.694646Z","shell.execute_reply":"2023-10-20T22:27:49.246381Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import json\nwith open(output_json_path, 'w', encoding='utf-8') as jsonl_file:\n    for item in formatted_dataset :\n        jsonl_file.write(json.dumps(item) + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:27:55.158044Z","iopub.execute_input":"2023-10-20T22:27:55.158833Z","iopub.status.idle":"2023-10-20T22:27:56.412927Z","shell.execute_reply.started":"2023-10-20T22:27:55.158798Z","shell.execute_reply":"2023-10-20T22:27:56.411890Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"raw_datasets = load_dataset(\n    \"json\",\n    data_files=\"english_to_hinglish.json\",\n  )","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:28:00.101062Z","iopub.execute_input":"2023-10-20T22:28:00.101891Z","iopub.status.idle":"2023-10-20T22:28:00.652345Z","shell.execute_reply.started":"2023-10-20T22:28:00.101859Z","shell.execute_reply":"2023-10-20T22:28:00.651428Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-a9faf385ec4e7638/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4562a1af1164fd68a7e861246944f71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ab398fbd584dd5981defbe5a177db9"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a9faf385ec4e7638/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fcd2a52cca9481e8348ec17f7c72cc5"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess(source_data):\n    inputs = [k[source_lang] for k in source_data['translation']]\n    targets = [k[target_lang] for k in source_data['translation']]\n    inputs = [source_prefix + inp for inp in inputs]\n    #using the previously trained tokenizer\n    model_inputs = trained_tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n    labels = trained_tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\n\n    labels[\"input_id\"] = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n    ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:28:09.818339Z","iopub.execute_input":"2023-10-20T22:28:09.819206Z","iopub.status.idle":"2023-10-20T22:28:09.826088Z","shell.execute_reply.started":"2023-10-20T22:28:09.819175Z","shell.execute_reply":"2023-10-20T22:28:09.825023Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:28:12.872808Z","iopub.execute_input":"2023-10-20T22:28:12.873598Z","iopub.status.idle":"2023-10-20T22:28:12.879133Z","shell.execute_reply.started":"2023-10-20T22:28:12.873566Z","shell.execute_reply":"2023-10-20T22:28:12.878227Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 189102\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:28:21.183356Z","iopub.execute_input":"2023-10-20T22:28:21.184089Z","iopub.status.idle":"2023-10-20T22:28:21.188121Z","shell.execute_reply.started":"2023-10-20T22:28:21.184057Z","shell.execute_reply":"2023-10-20T22:28:21.186961Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess, batched=True, remove_columns=\"translation\")","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:30:24.825401Z","iopub.execute_input":"2023-10-20T22:30:24.826132Z","iopub.status.idle":"2023-10-20T22:31:30.937703Z","shell.execute_reply.started":"2023-10-20T22:30:24.826099Z","shell.execute_reply":"2023-10-20T22:31:30.936956Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/190 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f2cc154147a499f975b4ec80b7c8d27"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import default_data_collator","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:31:33.576224Z","iopub.execute_input":"2023-10-20T22:31:33.577077Z","iopub.status.idle":"2023-10-20T22:31:33.919770Z","shell.execute_reply.started":"2023-10-20T22:31:33.577043Z","shell.execute_reply":"2023-10-20T22:31:33.919024Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data_collator = default_data_collator\n\ntrainer_args_in = {\n    'output_dir': 'full-hinglish-translator',\n    'overwrite_output_dir' : True,\n    'do_train' : True,\n    # 'do_valid' : False,\n    'per_device_train_batch_size' : 8,\n    'num_train_epochs' : num_epochs,\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:31:38.431254Z","iopub.execute_input":"2023-10-20T22:31:38.431584Z","iopub.status.idle":"2023-10-20T22:31:38.436305Z","shell.execute_reply.started":"2023-10-20T22:31:38.431560Z","shell.execute_reply":"2023-10-20T22:31:38.435374Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, HfArgumentParser\nparser = HfArgumentParser((Seq2SeqTrainingArguments))\ntraining_args = parser.parse_dict(trainer_args_in)\n\ntrainer = Seq2SeqTrainer(model=model, args=training_args[0], train_dataset=train_dataset, tokenizer=trained_tokenizer, data_collator=data_collator)\n\ntrain_result = trainer.train(resume_from_checkpoint=None)\ntrainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:31:43.517212Z","iopub.execute_input":"2023-10-20T22:31:43.517541Z","iopub.status.idle":"2023-10-20T22:59:59.550591Z","shell.execute_reply.started":"2023-10-20T22:31:43.517517Z","shell.execute_reply":"2023-10-20T22:59:59.549056Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231020_223315-fsoxve52</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/profiecientvision/huggingface/runs/fsoxve52' target=\"_blank\">stellar-pond-1</a></strong> to <a href='https://wandb.ai/profiecientvision/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/profiecientvision/huggingface' target=\"_blank\">https://wandb.ai/profiecientvision/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/profiecientvision/huggingface/runs/fsoxve52' target=\"_blank\">https://wandb.ai/profiecientvision/huggingface/runs/fsoxve52</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='14501' max='70914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14501/70914 26:07 < 1:41:37, 9.25 it/s, Epoch 0.61/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.829900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.494900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.451000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.429400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.399500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.395500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.386200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.369100</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.350600</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.350900</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.340100</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.325600</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.325100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.319900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.306400</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.302100</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.304200</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.291700</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.295500</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.284500</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.285000</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.287700</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.271000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.262500</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.274400</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.268100</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.264500</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.257800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/2: file write failed","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_dict(trainer_args_in)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39mtraining_args[\u001b[38;5;241m0\u001b[39m], train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, tokenizer\u001b[38;5;241m=\u001b[39mtrained_tokenizer, data_collator\u001b[38;5;241m=\u001b[39mdata_collator)\n\u001b[0;32m----> 7\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1927\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1927\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2265\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2265\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2362\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2354\u001b[0m         smp\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m   2355\u001b[0m             opt_state_dict,\n\u001b[1;32m   2356\u001b[0m             os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, OPTIMIZER_NAME),\n\u001b[1;32m   2357\u001b[0m             partial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2358\u001b[0m             v3\u001b[38;5;241m=\u001b[39msmp\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mshard_optimizer_state,\n\u001b[1;32m   2359\u001b[0m         )\n\u001b[1;32m   2360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfsdp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_enabled):\n\u001b[1;32m   2361\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 2362\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:337] . unexpected pos 200064704 vs 200064592"],"ename":"RuntimeError","evalue":"[enforce fail at inline_container.cc:337] . unexpected pos 200064704 vs 200064592","output_type":"error"},{"name":"stderr","text":"--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 144, in handle_request\n    logger.debug(f\"handle_request: {request_type}\")\nMessage: 'handle_request: keepalive'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n    self._sm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1552, in finish\n    logger.info(\"shutting down sender\")\nMessage: 'shutting down sender'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n    self._hm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 861, in finish\n    logger.info(\"shutting down handler\")\nMessage: 'shutting down handler'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 368, in dispatch_events\n    handler.dispatch(event)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/events.py\", line 454, in dispatch\n    _method_map[event_type](event)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 271, in _on_file_created\n    logger.info(\"file/dir created: %s\", event.src_path)\nMessage: 'file/dir created: %s'\nArguments: ('/kaggle/working/wandb/run-20231020_223315-fsoxve52/files/output.log',)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 48, in run\n    self._target(**self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 174, in wandb_internal\n    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\nMessage: 'Thread SenderThread:'\nArguments: ()\nThread SenderThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n    self._sm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1555, in finish\n    self._output_raw_finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1194, in _output_raw_finish\n    self._output_raw_flush(stream)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1241, in _output_raw_flush\n    self._output_raw_file.write(data.encode(\"utf-8\"))\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 79, in write\n    super().write(b\"\\n\".join(ret) + b\"\\n\")\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 46, in write\n    self.f.flush()\nOSError: [Errno 28] No space left on device\nwandb: ERROR Internal wandb error: file data was not synced\n","output_type":"stream"}]},{"cell_type":"code","source":"pip show transformers","metadata":{"execution":{"iopub.status.busy":"2023-10-20T22:24:18.791988Z","iopub.status.idle":"2023-10-20T22:24:18.792291Z","shell.execute_reply.started":"2023-10-20T22:24:18.792139Z","shell.execute_reply":"2023-10-20T22:24:18.792154Z"},"trusted":true},"execution_count":null,"outputs":[]}]}